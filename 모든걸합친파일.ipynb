{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.0 ; cuda:  2.0.0\n",
      "detectron2: 0.2.1\n",
      "True\n",
      "2.0.0 True\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/13 17:22:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/13 17:22:22 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/13 17:22:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/13 17:22:22 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import time\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import torchvision\n",
    "import requests\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"ball\", {}, 'dataset/output_100.json', 'dataset')\n",
    "register_coco_instances(\"bat\", {}, 'dataset/output_100.json', 'dataset')\n",
    "\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"ball\", \"bat\")\n",
    "cfg.DATASETS.TEST = (\"ball\", \"bat\")\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")   # Let training initialize from model zoo\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # two class(ball, bat)\n",
    "\n",
    "# ->> 처리\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final_bat.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"ball\", \"bat\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "#---- 선수 맞은편 카메라\n",
    "cfg2 = get_cfg()\n",
    "cfg2.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg2.DATASETS.TRAIN = (\"ball\",)\n",
    "cfg2.DATASETS.TEST = (\"ball\", )\n",
    "cfg2.DATALOADER.NUM_WORKERS = 2\n",
    "cfg2.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")   # Let training initialize from model zoo\n",
    "cfg2.MODEL.ROI_HEADS.NUM_CLASSES = 1 # one class(ball)\n",
    "\n",
    "# ->> 처리\n",
    "cfg2.MODEL.WEIGHTS = os.path.join(cfg2.OUTPUT_DIR, \"model_final_ball.pth\")\n",
    "cfg2.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\n",
    "cfg2.DATASETS.TEST = (\"ball\",)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "#----- 끝\n",
    "\n",
    "# 함수 선언부\n",
    "def lines_intersect(line1, line2):\n",
    "    \"\"\"Return True if line segment 'line1' and 'line2' intersect. False otherwise.\"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "\n",
    "    # Compute vectors corresponding to lines\n",
    "    px = x2 - x1\n",
    "    py = y2 - y1\n",
    "    qx = x4 - x3\n",
    "    qy = y4 - y3\n",
    "\n",
    "    # Cross product of vectors to determine if parallel\n",
    "    cross_product = px * qy - qx * py\n",
    "    if abs(cross_product) < 1e-8: # consider as zero\n",
    "        return False  # parallel\n",
    "\n",
    "    # Compute the intersection point\n",
    "    dx = x1 - x3\n",
    "    dy = y1 - y3\n",
    "    t = (qx * dy - qy * dx) / cross_product\n",
    "    u = (px * dy - py * dx) / cross_product\n",
    "\n",
    "    return (0 <= t <= 1) and (0 <= u <= 1)\n",
    "\n",
    "# 함수 선언부 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 21:26:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 21:26:22 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 21:26:22 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 21:26:22 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ball Coordinates:\n",
      "측면 카메라: False\n",
      "홈플레이트 카메라: 1\n",
      "ball\n"
     ]
    }
   ],
   "source": [
    "# 각 파일 path\n",
    "protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"pose_iter_160000.caffemodel\"\n",
    " \n",
    "# Create predictor and metadata objects\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "\n",
    "# 위의 path에 있는 network 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA) #벡엔드로 쿠다를 사용하여 속도향상을 꾀한다\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA) # 쿠다 디바이스에 계산 요청\n",
    "\n",
    "inputWidth=320;\n",
    "inputHeight=240;\n",
    "inputScale=1.0/255;\n",
    "\n",
    "start_time = time.time() # 시작 시간\n",
    "ball_coordinates = []\n",
    "points_buffer = {2: [], 8: [], 9: []} # 버퍼 초기화\n",
    "drawn_line = None\n",
    "line_timestamp = None  # 선의 타임스탬프 변수 초기화\n",
    "\n",
    "# 선수 신체부위 추출용 끝\n",
    "\n",
    "video_path1 = 'dataset/test15.mp4' # 측면카메라\n",
    "cap1 = cv2.VideoCapture(video_path1)\n",
    "\n",
    "video_path2 = 'dataset/test15.mp4' # 홈플레이트 카메라\n",
    "cap2 = cv2.VideoCapture(video_path2)\n",
    "\n",
    "while cv2.waitKey(1) <0:  #아무 키나 누르면 끝난다.\n",
    "    #웹캠으로부터 영상 가져옴\n",
    "    hasFrame, frame = cap1.read()  \n",
    "    hasFrame2, frame2 = cap2.read() # 홈플레이트\n",
    "\n",
    "    #영상이 커서 느리면 사이즈를 줄이자\n",
    "    #frame=cv2.resize(frame,dsize=(1200,800),interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    #웹캠으로부터 영상을 가져올 수 없으면 웹캠 중지\n",
    "    if not hasFrame or not hasFrame2:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "    \n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    \n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, inputScale, (inputWidth, inputHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    \n",
    "    imgb=cv2.dnn.imagesFromBlob(inpBlob)\n",
    "    #cv2.imshow(\"motion\",(imgb[0]*255.0).astype(np.uint8))\n",
    "    \n",
    "    # network에 넣어주기\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    output = net.forward()\n",
    "    \n",
    "    outputs = predictor2(frame)\n",
    "    v = Visualizer(frame[:, :, ::-1], metadata=ball_metadata)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    confidence_threshold = 0.8 # Set your desired confidence threshold here\n",
    "\n",
    "    for i in range(len(instances)):\n",
    "        if instances.pred_classes[i] == 0: # 0번 클래스는 공입니다.\n",
    "            confidence = instances.scores[i]\n",
    "            if confidence > confidence_threshold:\n",
    "                bbox = instances.pred_boxes[i]\n",
    "                x1, y1, x2, y2 = bbox.tensor.numpy()[0]\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "                radius = int((x2 - x1 + y2 - y1) / 4)\n",
    "                cv2.circle(frame, (center_x, center_y), radius, (255, 0, 0), thickness=2)\n",
    "                ball_coordinates.append((center_x, center_y))  # Add ball coordinates\n",
    "\n",
    "    out = v.draw_instance_predictions(instances)\n",
    "\n",
    "    # 키포인트 검출시 이미지에 그려줌\n",
    "    points = []\n",
    "    for i in [2,8,9]:\n",
    "        # 해당 신체부위 신뢰도 얻음.\n",
    "        probMap = output[0, i, :, :]\n",
    "    \n",
    "        # global 최대값 찾기\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # 원래 이미지에 맞게 점 위치 변경\n",
    "        x = (frameWidth * point[0]) / output.shape[3]\n",
    "        y = (frameHeight * point[1]) / output.shape[2]\n",
    "\n",
    "        # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "        if prob > 0.1 :   \n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "            cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "            points_buffer[i].append((x, y))  # 버퍼에 점 추가\n",
    "        else :\n",
    "            points.append(None)\n",
    "            points_buffer[i] = []  # 버퍼 클리어\n",
    "\n",
    "    # 각 점의 버퍼가 1초 이상의 데이터를 가지고 있다면\n",
    "    if all([len(points_buffer[i]) >= 1*10 for i in [2, 8, 9]]):\n",
    "        # 각 점의 평균 계산\n",
    "        avg_points = {i: np.mean(points_buffer[i], axis=0) for i in [2, 8, 9]}\n",
    "        shoulder_avg, waist_avg, knee_avg = avg_points[2], avg_points[8], avg_points[9]\n",
    "        cal_avg = waist_avg[1] + ((shoulder_avg[1]-waist_avg[1])/2)\n",
    "\n",
    "        # Draw the line\n",
    "        drawn_line = (int(knee_avg[0]), int(knee_avg[1]), int(knee_avg[0]), int(cal_avg))\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "\n",
    "    # 키 포인트 중 하나라도 감지되지 않으면, 최소 1초가 지났는지 확인\n",
    "    if any(pt is None for pt in points):\n",
    "        if line_timestamp is None or time.time() - line_timestamp >= 1:\n",
    "            drawn_line = None\n",
    "            line_timestamp = None\n",
    "\n",
    "    # 이전에 선이 그려졌다면, 그 선을 그리고 타임스탬프를 업데이트\n",
    "    if drawn_line is not None:\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "        line_timestamp = time.time()\n",
    "    \n",
    "    cv2.imshow(\"Side Camera\",frame)\n",
    "# -----------홈플레이트 카메라 부분---------------\n",
    "    outputs2 = predictor(frame2)\n",
    "    v2 = Visualizer(frame2[:, :, ::-1], metadata=ball_metadata, scale=1)\n",
    "    out2 = v2.draw_instance_predictions(outputs2[\"instances\"].to(\"cpu\"))\n",
    "    output_frame2 = out2.get_image()[:, :, ::-1]\n",
    "    instances2 = outputs2[\"instances\"].to(\"cpu\")\n",
    "    num_objects2 = len(instances2)\n",
    "\n",
    "    cv2.imshow(\"Homeplate Camera\",output_frame2)\n",
    "# ------------------------------------------------\n",
    "\n",
    "print(\"Ball Coordinates:\")\n",
    "for point in ball_coordinates:\n",
    "    print(point)\n",
    "\n",
    "strike1 = False  # Initialize strike variable 선수 맞은편 카메라 스트라이크 판정 \n",
    "strike2 = False # 홈플레이트 판정\n",
    "final_strike = False # 최종 스트라이크 판정\n",
    "\n",
    "for i in range(1, len(ball_coordinates)):\n",
    "    ball_trajectory = (*ball_coordinates[i-1], *ball_coordinates[i])  # Get the line of ball's trajectory\n",
    "\n",
    "    if drawn_line is not None and lines_intersect(ball_trajectory, drawn_line):\n",
    "        strike1 = True\n",
    "        break  # Exit the loop if a strike is detected\n",
    "    else:\n",
    "         strike1 = False\n",
    "\n",
    "if num_objects2 > 0:\n",
    "    strike2 = True\n",
    "else:\n",
    "    strike2 = False\n",
    "        \n",
    "print(\"측면 카메라:\", strike1)\n",
    "print(\"홈플레이트 카메라:\", num_objects2)\n",
    "\n",
    "# 스트라이크\n",
    "if strike1 == True and strike2 == True:\n",
    "    final_strike = True\n",
    "    print(\"strike!!\")\n",
    "# 볼\n",
    "else:\n",
    "    final_strike = False\n",
    "    print(\"ball\") \n",
    "        \n",
    "cap2.release()  #카메라 장치에서 받아온 메모리 해제\n",
    "cv2.destroyAllWindows() #모든 윈도우 창 닫음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.0 ; cuda:  2.0.0\n",
      "detectron2: 0.2.1\n",
      "True\n",
      "2.0.0 True\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/17 01:19:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/17 01:19:39 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/17 01:19:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/17 01:19:39 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import time\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import torchvision\n",
    "import requests\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"ball\", {}, 'dataset/output_100.json', 'dataset')\n",
    "register_coco_instances(\"bat\", {}, 'dataset/output_100.json', 'dataset')\n",
    "\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"ball\", \"bat\")\n",
    "cfg.DATASETS.TEST = (\"ball\", \"bat\")\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")   # Let training initialize from model zoo\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # two class(ball, bat)\n",
    "\n",
    "# ->> 처리\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final_bat.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"ball\", \"bat\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "#---- 선수 맞은편 카메라\n",
    "cfg2 = get_cfg()\n",
    "cfg2.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg2.DATASETS.TRAIN = (\"ball\",)\n",
    "cfg2.DATASETS.TEST = (\"ball\", )\n",
    "cfg2.DATALOADER.NUM_WORKERS = 2\n",
    "cfg2.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")   # Let training initialize from model zoo\n",
    "cfg2.MODEL.ROI_HEADS.NUM_CLASSES = 1 # one class(ball)\n",
    "\n",
    "# ->> 처리\n",
    "cfg2.MODEL.WEIGHTS = os.path.join(cfg2.OUTPUT_DIR, \"model_final_ball.pth\")\n",
    "cfg2.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\n",
    "cfg2.DATASETS.TEST = (\"ball\",)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "#----- 끝\n",
    "\n",
    "# 함수 선언부\n",
    "def lines_intersect(line1, line2):\n",
    "    \"\"\"Return True if line segment 'line1' and 'line2' intersect. False otherwise.\"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "\n",
    "    # Compute vectors corresponding to lines\n",
    "    px = x2 - x1\n",
    "    py = y2 - y1\n",
    "    qx = x4 - x3\n",
    "    qy = y4 - y3\n",
    "\n",
    "    # Cross product of vectors to determine if parallel\n",
    "    cross_product = px * qy - qx * py\n",
    "    if abs(cross_product) < 1e-8: # consider as zero\n",
    "        return False  # parallel\n",
    "\n",
    "    # Compute the intersection point\n",
    "    dx = x1 - x3\n",
    "    dy = y1 - y3\n",
    "    t = (qx * dy - qy * dx) / cross_product\n",
    "    u = (px * dy - py * dx) / cross_product\n",
    "\n",
    "    return (0 <= t <= 1) and (0 <= u <= 1)\n",
    "\n",
    "# 함수 선언부 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 23:00:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 23:00:20 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 23:00:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 23:00:20 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ball Coordinates:\n",
      "(379, 50)\n",
      "(379, 50)\n",
      "(371, 216)\n",
      "(363, 411)\n",
      "(356, 649)\n",
      "측면 카메라: False\n",
      "strike_line_left: 144\n",
      "strike_line_right 576\n",
      "ball_indices []\n",
      "홈플레이트 카메라: 0\n",
      "홈플레이트 카메라: False\n",
      "ball\n"
     ]
    }
   ],
   "source": [
    "# 각 파일 path\n",
    "protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"pose_iter_160000.caffemodel\"\n",
    " \n",
    "# Create predictor and metadata objects\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "\n",
    "# 위의 path에 있는 network 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA) #벡엔드로 쿠다를 사용하여 속도향상을 꾀한다\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA) # 쿠다 디바이스에 계산 요청\n",
    "\n",
    "inputWidth=320;\n",
    "inputHeight=240;\n",
    "inputScale=1.0/255;\n",
    "\n",
    "start_time = time.time() # 시작 시간\n",
    "ball_coordinates = []\n",
    "points_buffer = {2: [], 8: [], 9: []} # 버퍼 초기화\n",
    "drawn_line = None\n",
    "line_timestamp = None  # 선의 타임스탬프 변수 초기화\n",
    "\n",
    "# 선수 신체부위 추출용 끝\n",
    "\n",
    "video_path1 = 'dataset/test19.mp4' # 측면카메라\n",
    "cap1 = cv2.VideoCapture(video_path1)\n",
    "\n",
    "video_path2 = 'dataset/test18.mp4' # 홈플레이트 카메라\n",
    "cap2 = cv2.VideoCapture(video_path2)\n",
    "\n",
    "while cv2.waitKey(1) <0:  #아무 키나 누르면 끝난다.\n",
    "    #웹캠으로부터 영상 가져옴\n",
    "    hasFrame, frame = cap1.read()  \n",
    "    hasFrame2, frame2 = cap2.read() # 홈플레이트\n",
    "    \n",
    "    #웹캠으로부터 영상을 가져올 수 없으면 웹캠 중지\n",
    "    if not hasFrame or not hasFrame2:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "    \n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth2 = frame2.shape[1]\n",
    "    frameHeight2 = frame2.shape[0]\n",
    "    \n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, inputScale, (inputWidth, inputHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    \n",
    "    imgb=cv2.dnn.imagesFromBlob(inpBlob)\n",
    "    \n",
    "    # network에 넣어주기\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    output = net.forward()\n",
    "    \n",
    "    outputs = predictor2(frame)\n",
    "    v = Visualizer(frame[:, :, ::-1], metadata=ball_metadata)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    confidence_threshold = 0.8 # Set your desired confidence threshold here\n",
    "\n",
    "    for i in range(len(instances)):\n",
    "        if instances.pred_classes[i] == 0: # 0번 클래스는 공입니다.\n",
    "            confidence = instances.scores[i]\n",
    "            if confidence > confidence_threshold:\n",
    "                bbox = instances.pred_boxes[i]\n",
    "                x1, y1, x2, y2 = bbox.tensor.numpy()[0]\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "                radius = int((x2 - x1 + y2 - y1) / 4)\n",
    "                cv2.circle(frame, (center_x, center_y), radius, (255, 0, 0), thickness=2)\n",
    "                ball_coordinates.append((center_x, center_y))  # Add ball coordinates\n",
    "\n",
    "    out = v.draw_instance_predictions(instances)\n",
    "\n",
    "    # 키포인트 검출시 이미지에 그려줌\n",
    "    points = []\n",
    "    for i in [2,8,9]:\n",
    "        # 해당 신체부위 신뢰도 얻음.\n",
    "        probMap = output[0, i, :, :]\n",
    "    \n",
    "        # global 최대값 찾기\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # 원래 이미지에 맞게 점 위치 변경\n",
    "        x = (frameWidth * point[0]) / output.shape[3]\n",
    "        y = (frameHeight * point[1]) / output.shape[2]\n",
    "\n",
    "        # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "        if prob > 0.1 :   \n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "            cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "            points_buffer[i].append((x, y))  # 버퍼에 점 추가\n",
    "        else :\n",
    "            points.append(None)\n",
    "            points_buffer[i] = []  # 버퍼 클리어\n",
    "\n",
    "    # 각 점의 버퍼가 1초 이상의 데이터를 가지고 있다면\n",
    "    if all([len(points_buffer[i]) >= 1*10 for i in [2, 8, 9]]):\n",
    "        # 각 점의 평균 계산\n",
    "        avg_points = {i: np.mean(points_buffer[i], axis=0) for i in [2, 8, 9]}\n",
    "        shoulder_avg, waist_avg, knee_avg = avg_points[2], avg_points[8], avg_points[9]\n",
    "        cal_avg = waist_avg[1] + ((shoulder_avg[1]-waist_avg[1])/2)\n",
    "\n",
    "        # Draw the line\n",
    "        drawn_line = (int(knee_avg[0]), int(knee_avg[1]), int(knee_avg[0]), int(cal_avg))\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "\n",
    "    # 키 포인트 중 하나라도 감지되지 않으면, 최소 1초가 지났는지 확인\n",
    "    if any(pt is None for pt in points):\n",
    "        if line_timestamp is None or time.time() - line_timestamp >= 1:\n",
    "            drawn_line = None\n",
    "            line_timestamp = None\n",
    "\n",
    "    # 이전에 선이 그려졌다면, 그 선을 그리고 타임스탬프를 업데이트\n",
    "    if drawn_line is not None:\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "        line_timestamp = time.time()\n",
    "    \n",
    "    cv2.imshow(\"Side Camera\",frame)\n",
    "# -----------홈플레이트 카메라 부분---------------\n",
    "    outputs2 = predictor(frame2)\n",
    "    v2 = Visualizer(frame2[:, :, ::-1], metadata=ball_metadata, scale=1)\n",
    "    out2 = v2.draw_instance_predictions(outputs2[\"instances\"].to(\"cpu\"))\n",
    "    output_frame2 = out2.get_image()[:, :, ::-1]\n",
    "    output_frame2 = np.array(output_frame2)\n",
    "    instances2 = outputs2[\"instances\"].to(\"cpu\")\n",
    "    num_objects2 = len(instances2)\n",
    "\n",
    "    strike_line_color = (0, 0, 255)  # 라인 색상 (빨간색)\n",
    "    strike_line_left = int(frameWidth2 * (20 / 100))  # 좌측 라인 좌표\n",
    "    strike_line_right = int(frameWidth2 * (80 / 100))  # 우측 라인 좌표\n",
    "    \n",
    "    center_line = frameHeight2 // 2\n",
    "\n",
    "    cv2.line(output_frame2, (strike_line_left, 0), (strike_line_left, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (strike_line_right, 0), (strike_line_right, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (0, int(center_line)), (frameWidth2, int(center_line)), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Homeplate Camera\", output_frame2)\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "print(\"Ball Coordinates:\")\n",
    "for point in ball_coordinates:\n",
    "    print(point)\n",
    "\n",
    "strike1 = False  # Initialize strike variable 선수 맞은편 카메라 스트라이크 판정 \n",
    "strike2 = False # 홈플레이트 판정\n",
    "final_strike = False # 최종 스트라이크 판정\n",
    "\n",
    "for i in range(1, len(ball_coordinates)):\n",
    "    ball_trajectory = (*ball_coordinates[i-1], *ball_coordinates[i])  # Get the line of ball's trajectory\n",
    "\n",
    "    if drawn_line is not None and lines_intersect(ball_trajectory, drawn_line):\n",
    "        strike1 = True\n",
    "        break  # Exit the loop if a strike is detected\n",
    "    else:\n",
    "         strike1 = False\n",
    "\n",
    "#---------------------홈플레이트 스트라이크/존 판정\n",
    "# 좌우 스트라이크 존 사이를 지나가는 공이 있을 경우\n",
    "ball_indices = [i for i, cls in enumerate(instances2.pred_classes) if cls == 0]  # 공 객체의 인덱스 추출\n",
    "\n",
    "if any((instances2.pred_boxes.tensor[i][0] > strike_line_left and instances2.pred_boxes.tensor[i][0] < strike_line_right) or\n",
    "       (instances2.pred_boxes.tensor[i][2] > strike_line_left and instances2.pred_boxes.tensor[i][2] < strike_line_right)\n",
    "    for i in ball_indices): # 0:왼쪽상단 2:아래하단 x좌표\n",
    "    strike2 = True\n",
    "else:\n",
    "    strike2 = False\n",
    "\n",
    "#------------- 배트가 중앙 선을 넘어갈 경우 strike판정, strike2가 final strike가 되어야 함\n",
    "bat_indices = [j for j, cls in enumerate(instances2.pred_classes) if cls == 1]  # 배트 객체의 인덱스 추출\n",
    "\n",
    "if any(instances2.pred_boxes.tensor[j][1] < center_line or instances2.pred_boxes.tensor[j][3] < center_line\n",
    "       for j in bat_indices): # 1:왼쪽상단 3:아래하단 y좌표\n",
    "    strike2 = True\n",
    "    final_strike = True\n",
    "    print(\"배트가 중앙선을 넘었습니다.\")\n",
    "else:\n",
    "    final_strike = False\n",
    "#--------------------------\n",
    "print(\"측면 카메라:\", strike1)\n",
    "print(\"strike_line_left:\", strike_line_left)\n",
    "print(\"strike_line_right\", strike_line_right)\n",
    "print(\"ball_indices\", ball_indices)\n",
    "print(\"홈플레이트 카메라:\", num_objects2)\n",
    "print(\"홈플레이트 카메라:\", strike2)\n",
    "\n",
    "# 스트라이크\n",
    "if strike1 == True and strike2 == True or final_strike == True:\n",
    "    final_strike = True\n",
    "    print(\"strike!!\")\n",
    "# 볼\n",
    "else:\n",
    "    final_strike = False\n",
    "    print(\"ball\") \n",
    "        \n",
    "cap2.release()  #카메라 장치에서 받아온 메모리 해제\n",
    "cv2.destroyAllWindows() #모든 윈도우 창 닫음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/17 01:51:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/17 01:51:39 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/17 01:51:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/17 01:51:39 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라: False\n",
      "홈플레이트 카메라: True\n",
      "strike!!\n"
     ]
    }
   ],
   "source": [
    "# 각 파일 path\n",
    "protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"pose_iter_160000.caffemodel\"\n",
    " \n",
    "# Create predictor and metadata objects\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "\n",
    "# 위의 path에 있는 network 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA) #벡엔드로 쿠다를 사용하여 속도향상을 꾀한다\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA) # 쿠다 디바이스에 계산 요청\n",
    "\n",
    "inputWidth=320;\n",
    "inputHeight=240;\n",
    "inputScale=1.0/255;\n",
    "\n",
    "start_time = time.time() # 시작 시간\n",
    "ball_coordinates = []\n",
    "ball_coordinates2 = []\n",
    "points_buffer = {2: [], 8: [], 9: []} # 버퍼 초기화\n",
    "drawn_line = None\n",
    "line_timestamp = None  # 선의 타임스탬프 변수 초기화\n",
    "\n",
    "# 선수 신체부위 추출용 끝\n",
    "\n",
    "video_path1 = 'dataset/test24.mp4' # 측면카메라\n",
    "cap1 = cv2.VideoCapture(video_path1)\n",
    "\n",
    "video_path2 = 'dataset/test25.mp4' # 홈플레이트 카메라\n",
    "cap2 = cv2.VideoCapture(video_path2)\n",
    "\n",
    "while cv2.waitKey(1) <0:  #아무 키나 누르면 끝난다.\n",
    "    #웹캠으로부터 영상 가져옴\n",
    "    hasFrame, frame = cap1.read()  \n",
    "    hasFrame2, frame2 = cap2.read() # 홈플레이트\n",
    "    \n",
    "    #웹캠으로부터 영상을 가져올 수 없으면 웹캠 중지\n",
    "    if not hasFrame or not hasFrame2:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "    \n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth2 = frame2.shape[1]\n",
    "    frameHeight2 = frame2.shape[0]\n",
    "    \n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, inputScale, (inputWidth, inputHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    \n",
    "    imgb=cv2.dnn.imagesFromBlob(inpBlob)\n",
    "    \n",
    "    # network에 넣어주기\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    output = net.forward()\n",
    "    \n",
    "    outputs = predictor2(frame)\n",
    "    v = Visualizer(frame[:, :, ::-1], metadata=ball_metadata)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    confidence_threshold = 0.8 # Set your desired confidence threshold here\n",
    "\n",
    "    for i in range(len(instances)):\n",
    "        if instances.pred_classes[i] == 0: # 0번 클래스는 공입니다.\n",
    "            confidence = instances.scores[i]\n",
    "            if confidence > confidence_threshold:\n",
    "                bbox = instances.pred_boxes[i]\n",
    "                x1, y1, x2, y2 = bbox.tensor.numpy()[0]\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "                radius = int((x2 - x1 + y2 - y1) / 4)\n",
    "                cv2.circle(frame, (center_x, center_y), radius, (255, 0, 0), thickness=2)\n",
    "                ball_coordinates.append((center_x, center_y))  # Add ball coordinates\n",
    "\n",
    "    out = v.draw_instance_predictions(instances)\n",
    "\n",
    "    # 키포인트 검출시 이미지에 그려줌\n",
    "    points = []\n",
    "    for i in [2,8,9]:\n",
    "        # 해당 신체부위 신뢰도 얻음.\n",
    "        probMap = output[0, i, :, :]\n",
    "    \n",
    "        # global 최대값 찾기\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # 원래 이미지에 맞게 점 위치 변경\n",
    "        x = (frameWidth * point[0]) / output.shape[3]\n",
    "        y = (frameHeight * point[1]) / output.shape[2]\n",
    "\n",
    "        # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "        if prob > 0.1 :   \n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "            cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "            points_buffer[i].append((x, y))  # 버퍼에 점 추가\n",
    "        else :\n",
    "            points.append(None)\n",
    "            points_buffer[i] = []  # 버퍼 클리어\n",
    "\n",
    "    # 각 점의 버퍼가 1초 이상의 데이터를 가지고 있다면\n",
    "    if all([len(points_buffer[i]) >= 2*10 for i in [2, 8, 9]]):\n",
    "        # 각 점의 평균 계산\n",
    "        avg_points = {i: np.mean(points_buffer[i], axis=0) for i in [2, 8, 9]}\n",
    "        shoulder_avg, waist_avg, knee_avg = avg_points[2], avg_points[8], avg_points[9]\n",
    "        cal_avg = waist_avg[1] + ((shoulder_avg[1]-waist_avg[1])/2)\n",
    "\n",
    "        # Draw the line\n",
    "        drawn_line = (int(knee_avg[0]), int(knee_avg[1]), int(knee_avg[0]), int(cal_avg))\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "\n",
    "    # 키 포인트 중 하나라도 감지되지 않으면, 최소 1초가 지났는지 확인\n",
    "    if any(pt is None for pt in points):\n",
    "        if line_timestamp is None or time.time() - line_timestamp >= 1:\n",
    "            drawn_line = None\n",
    "            line_timestamp = None\n",
    "\n",
    "    # 이전에 선이 그려졌다면, 그 선을 그리고 타임스탬프를 업데이트\n",
    "    if drawn_line is not None:\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "        line_timestamp = time.time()\n",
    "    \n",
    "    cv2.imshow(\"Side Camera\",frame)\n",
    "# -----------홈플레이트 카메라 부분---------------\n",
    "    outputs2 = predictor(frame2)\n",
    "    v2 = Visualizer(frame2[:, :, ::-1], metadata=ball_metadata, scale=1)\n",
    "    out2 = v2.draw_instance_predictions(outputs2[\"instances\"].to(\"cpu\"))\n",
    "    output_frame2 = out2.get_image()[:, :, ::-1]\n",
    "    output_frame2 = np.array(output_frame2)\n",
    "    instances2 = outputs2[\"instances\"].to(\"cpu\")\n",
    "    \n",
    "    for i in range(len(instances2)):\n",
    "        if instances2.pred_classes[i] == 0: # 0번 클래스는 공입니다.\n",
    "                bbox = instances2.pred_boxes[i]\n",
    "                x1, y1, x2, y2 = bbox.tensor.numpy()[0]\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "                radius = int((x2 - x1 + y2 - y1) / 4)\n",
    "                cv2.circle(frame, (center_x, center_y), radius, (255, 0, 0), thickness=2)\n",
    "                ball_coordinates2.append((center_x, center_y))  # Add ball coordinates\n",
    "                \n",
    "    num_objects2 = len(instances2)\n",
    "\n",
    "    strike_line_color = (0, 0, 255)  # 라인 색상 (빨간색)\n",
    "    strike_line_left = int(frameWidth2 * (20 / 100))  # 좌측 라인 좌표\n",
    "    strike_line_right = int(frameWidth2 * (80 / 100))  # 우측 라인 좌표\n",
    "    \n",
    "    center_line = frameHeight2 // 2\n",
    "\n",
    "    cv2.line(output_frame2, (strike_line_left, 0), (strike_line_left, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (strike_line_right, 0), (strike_line_right, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (0, int(center_line)), (frameWidth2, int(center_line)), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Homeplate Camera\", output_frame2)\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "# print(\"Ball Coordinates:\")\n",
    "# for point in ball_coordinates:\n",
    "#     print(point)\n",
    "    \n",
    "# print(\"Ball Coordinates2:\")\n",
    "# for point in ball_coordinates2:\n",
    "#     print(point)\n",
    "\n",
    "strike1 = False  # Initialize strike variable 선수 맞은편 카메라 스트라이크 판정 \n",
    "strike2 = False # 홈플레이트 판정\n",
    "final_strike = False # 최종 스트라이크 판정\n",
    "print(\"배트가 중앙선을 넘었습니다.\")\n",
    "\n",
    "#------------- 배트가 중앙 선을 넘어갈 경우 strike판정, strike2가 final strike가 되어야 함\n",
    "bat_indices = [j for j, cls in enumerate(instances2.pred_classes) if cls == 1]  # 배트 객체의 인덱스 추출\n",
    "\n",
    "if any(instances2.pred_boxes.tensor[j][1] < center_line or instances2.pred_boxes.tensor[j][3] < center_line\n",
    "       for j in bat_indices): # 1:왼쪽상단 3:아래하단 y좌표\n",
    "    final_strike = True\n",
    "    print(\"배트가 중앙선을 넘었습니다.\")\n",
    "else:\n",
    "    final_strike = True\n",
    "    \n",
    "#--------------------------\n",
    "\n",
    "for i in range(1, len(ball_coordinates)):\n",
    "    ball_trajectory = (*ball_coordinates[i-1], *ball_coordinates[i])  # Get the line of ball's trajectory\n",
    "\n",
    "    if drawn_line is not None and lines_intersect(ball_trajectory, drawn_line):\n",
    "        strike1 = True\n",
    "        break  # Exit the loop if a strike is detected\n",
    "    else:\n",
    "         strike1 = False\n",
    "\n",
    "#---------------------홈플레이트 스트라이크/존 판정\n",
    "# 좌우 스트라이크 존 사이를 지나가는 공이 있을 경우\n",
    "for ball_coord in ball_coordinates2:\n",
    "    ball_x, ball_y = ball_coord # 공의 x, y 좌표 추출\n",
    "\n",
    "    # 공의 x 좌표가 strike_line_left와 strike_line_right 사이에 위치하면 strike2를 True로 설정\n",
    "    if strike_line_left <= ball_x <= strike_line_right:\n",
    "        strike2 = True\n",
    "    else:\n",
    "        strike2 = False\n",
    "\n",
    "#--------------------------\n",
    "print(\"측면 카메라:\", strike1)\n",
    "# print(\"strike_line_left:\", strike_line_left)\n",
    "# print(\"strike_line_right\", strike_line_right)\n",
    "# print(\"ball_indices\", ball_indices)\n",
    "# print(\"홈플레이트 카메라:\", num_objects2)\n",
    "print(\"홈플레이트 카메라:\", strike2)\n",
    "\n",
    "# 스트라이크\n",
    "if strike1 == True and strike2 == True or final_strike == True:\n",
    "    final_strike = True\n",
    "    print(\"strike!!\")\n",
    "# 볼\n",
    "else:\n",
    "    final_strike = False\n",
    "    print(\"ball\") \n",
    "        \n",
    "cap2.release()  #카메라 장치에서 받아온 메모리 해제\n",
    "cv2.destroyAllWindows() #모든 윈도우 창 닫음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 23:31:56 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 23:31:56 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/16 23:31:56 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/16 23:31:56 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ball Coordinates:\n",
      "(379, 50)\n",
      "(379, 50)\n",
      "(371, 216)\n",
      "(363, 411)\n",
      "측면 카메라 스트라이크 판정: False\n",
      "홈플레이트 카메라 스트라이크 판정 :  True\n",
      "최종 스트라이크 판별 :  False\n"
     ]
    }
   ],
   "source": [
    "# 각 파일 path\n",
    "protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"pose_iter_160000.caffemodel\"\n",
    " \n",
    "# Create predictor and metadata objects\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "\n",
    "# 위의 path에 있는 network 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA) #벡엔드로 쿠다를 사용하여 속도향상을 꾀한다\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA) # 쿠다 디바이스에 계산 요청\n",
    "\n",
    "inputWidth=320;\n",
    "inputHeight=240;\n",
    "inputScale=1.0/255;\n",
    "\n",
    "start_time = time.time() # 시작 시간\n",
    "ball_coordinates = []\n",
    "points_buffer = {2: [], 8: [], 9: []} # 버퍼 초기화\n",
    "drawn_line = None\n",
    "line_timestamp = None  # 선의 타임스탬프 변수 초기화\n",
    "\n",
    "strike1 = False  # Initialize strike variable 선수 맞은편 카메라 스트라이크 판정 \n",
    "strike2 = False # 홈플레이트 판정\n",
    "final_strike = False # 최종 스트라이크 판정\n",
    "\n",
    "# 선수 신체부위 추출용 끝\n",
    "\n",
    "video_path1 = 'dataset/test19.mp4' # 측면카메라\n",
    "cap1 = cv2.VideoCapture(video_path1)\n",
    "\n",
    "video_path2 = 'dataset/test19.mp4' # 홈플레이트 카메라\n",
    "cap2 = cv2.VideoCapture(video_path2)\n",
    "\n",
    "while cv2.waitKey(1) <0:  #아무 키나 누르면 끝난다.\n",
    "    #웹캠으로부터 영상 가져옴\n",
    "    hasFrame, frame = cap1.read()  \n",
    "    hasFrame2, frame2 = cap2.read() # 홈플레이트\n",
    "    \n",
    "    #웹캠으로부터 영상을 가져올 수 없으면 웹캠 중지\n",
    "    if not hasFrame or not hasFrame2:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "    \n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "\n",
    "    frameWidth2 = frame2.shape[1]\n",
    "    frameHeight2 = frame2.shape[0]\n",
    "    \n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, inputScale, (inputWidth, inputHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    \n",
    "    imgb=cv2.dnn.imagesFromBlob(inpBlob)\n",
    "    \n",
    "    # network에 넣어주기\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    output = net.forward()\n",
    "    \n",
    "    outputs = predictor2(frame)\n",
    "    v = Visualizer(frame[:, :, ::-1], metadata=ball_metadata)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    confidence_threshold = 0.8 # Set your desired confidence threshold here\n",
    "\n",
    "    for i in range(len(instances)):\n",
    "        if instances.pred_classes[i] == 0: # 0번 클래스는 공입니다.\n",
    "            confidence = instances.scores[i]\n",
    "            if confidence > confidence_threshold:\n",
    "                bbox = instances.pred_boxes[i]\n",
    "                x1, y1, x2, y2 = bbox.tensor.numpy()[0]\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "                radius = int((x2 - x1 + y2 - y1) / 4)\n",
    "                cv2.circle(frame, (center_x, center_y), radius, (255, 0, 0), thickness=2)\n",
    "                ball_coordinates.append((center_x, center_y))  # Add ball coordinates\n",
    "\n",
    "    out = v.draw_instance_predictions(instances)\n",
    "\n",
    "    # 키포인트 검출시 이미지에 그려줌\n",
    "    points = []\n",
    "    for i in [2,8,9]:\n",
    "        # 해당 신체부위 신뢰도 얻음.\n",
    "        probMap = output[0, i, :, :]\n",
    "    \n",
    "        # global 최대값 찾기\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # 원래 이미지에 맞게 점 위치 변경\n",
    "        x = (frameWidth * point[0]) / output.shape[3]\n",
    "        y = (frameHeight * point[1]) / output.shape[2]\n",
    "\n",
    "        # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "        if prob > 0.1 :   \n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "            cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "            points_buffer[i].append((x, y))  # 버퍼에 점 추가\n",
    "        else :\n",
    "            points.append(None)\n",
    "            points_buffer[i] = []  # 버퍼 클리어\n",
    "\n",
    "    # 각 점의 버퍼가 1초 이상의 데이터를 가지고 있다면\n",
    "    if all([len(points_buffer[i]) >= 1*10 for i in [2, 8, 9]]):\n",
    "        # 각 점의 평균 계산\n",
    "        avg_points = {i: np.mean(points_buffer[i], axis=0) for i in [2, 8, 9]}\n",
    "        shoulder_avg, waist_avg, knee_avg = avg_points[2], avg_points[8], avg_points[9]\n",
    "        cal_avg = waist_avg[1] + ((shoulder_avg[1]-waist_avg[1])/2)\n",
    "\n",
    "        # Draw the line\n",
    "        drawn_line = (int(knee_avg[0]), int(knee_avg[1]), int(knee_avg[0]), int(cal_avg))\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "\n",
    "    # 키 포인트 중 하나라도 감지되지 않으면, 최소 1초가 지났는지 확인\n",
    "    if any(pt is None for pt in points):\n",
    "        if line_timestamp is None or time.time() - line_timestamp >= 1:\n",
    "            drawn_line = None\n",
    "            line_timestamp = None\n",
    "\n",
    "    # 이전에 선이 그려졌다면, 그 선을 그리고 타임스탬프를 업데이트\n",
    "    if drawn_line is not None:\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "        line_timestamp = time.time()\n",
    "    \n",
    "    cv2.imshow(\"Side Camera\",frame)\n",
    "# -----------홈플레이트 카메라 부분---------------\n",
    "    outputs2 = predictor(frame2)\n",
    "    v2 = Visualizer(frame2[:, :, ::-1], metadata=ball_metadata, scale=1)\n",
    "    out2 = v2.draw_instance_predictions(outputs2[\"instances\"].to(\"cpu\"))\n",
    "    output_frame2 = out2.get_image()[:, :, ::-1]\n",
    "    output_frame2 = np.array(output_frame2)\n",
    "    instances2 = outputs2[\"instances\"].to(\"cpu\")\n",
    "    num_objects2 = len(instances2)\n",
    "\n",
    "    strike_line_color = (0, 0, 255)  # 라인 색상 (빨간색)\n",
    "    strike_line_left = frameWidth2 * 2 // 10  # 좌측 라인 좌표\n",
    "    strike_line_right = frameWidth2 * 8 // 10  # 우측 라인 좌표\n",
    "    center_line = frameHeight2 // 2\n",
    "\n",
    "    cv2.line(output_frame2, (strike_line_left, 0), (strike_line_left, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (strike_line_right, 0), (strike_line_right, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (0, int(center_line)), (frameWidth2, int(center_line)), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Homeplate Camera\", output_frame2)\n",
    "\n",
    "    ball_indices = [i for i, cls in enumerate(instances2.pred_classes) if cls == 0]  # 공 객체의 인덱스 추출\n",
    "\n",
    "    if any((instances2.pred_boxes.tensor[i][0] > strike_line_left and instances2.pred_boxes.tensor[i][0] < strike_line_right) or\n",
    "           (instances2.pred_boxes.tensor[i][2] > strike_line_left and instances2.pred_boxes.tensor[i][2] < strike_line_right)\n",
    "           for i in ball_indices): # 0:왼쪽상단 2:아래하단 x좌표\n",
    "        strike2 = True\n",
    "    else:\n",
    "        strike2 = False\n",
    "\n",
    "    # 배트 객체 인식 확인\n",
    "    bat_indices = [j for j, cls in enumerate(instances2.pred_classes) if cls == 1]  # 배트 객체의 인덱스 추출\n",
    "\n",
    "    if any(instances2.pred_boxes.tensor[j][1] < center_line or instances2.pred_boxes.tensor[j][3] < center_line\n",
    "           for j in bat_indices): # 1:왼쪽상단 3:아래하단 y좌표\n",
    "        final_strike = True\n",
    "    else:\n",
    "        final_strike = False\n",
    "# ------------------------------------------------\n",
    "\n",
    "print(\"Ball Coordinates:\")\n",
    "for point in ball_coordinates:\n",
    "    print(point)\n",
    "\n",
    "for i in range(1, len(ball_coordinates)):\n",
    "    ball_trajectory = (*ball_coordinates[i-1], *ball_coordinates[i])  # Get the line of ball's trajectory\n",
    "\n",
    "    if drawn_line is not None and lines_intersect(ball_trajectory, drawn_line):\n",
    "        strike1 = True\n",
    "        break  # Exit the loop if a strike is detected\n",
    "    else:\n",
    "         strike1 = False\n",
    "\n",
    "#--------------------------\n",
    "print(\"측면 카메라 스트라이크 판정:\", strike1)\n",
    "print(\"홈플레이트 카메라 스트라이크 판정 : \", strike2)\n",
    "print(\"최종 스트라이크 판별 : \", final_strike)\n",
    "\n",
    "# 스트라이크\n",
    "if strike1 == True and strike2 == True:\n",
    "    final_strike = True\n",
    "    print(\"양쪽 다 strike!!\")\n",
    "# 볼\n",
    "# else:\n",
    "#     final_strike = False\n",
    "#     print(\"ball\") \n",
    "        \n",
    "cap2.release()  #카메라 장치에서 받아온 메모리 해제\n",
    "cv2.destroyAllWindows() #모든 윈도우 창 닫음\n",
    "\n",
    "# 2023-06-16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  2.0 ; cuda:  2.0.0\n",
      "detectron2: 0.2.1\n",
      "True\n",
      "2.0.0 True\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/02 16:17:21 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/02 16:17:21 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/02 16:17:21 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/02 16:17:21 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import torch, detectron2\n",
    "# TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "# CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "# print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "# print(\"detectron2:\", detectron2.__version__)\n",
    "# print(torch.cuda.is_available())\n",
    "\n",
    "# import detectron2\n",
    "# from detectron2.utils.logger import setup_logger\n",
    "# from detectron2.utils.visualizer import Visualizer\n",
    "# setup_logger()\n",
    "\n",
    "# import numpy as np\n",
    "# import os, json, cv2, random\n",
    "\n",
    "# from detectron2 import model_zoo\n",
    "# from detectron2.engine import DefaultPredictor\n",
    "# from detectron2.config import get_cfg\n",
    "# from detectron2.utils.visualizer import Visualizer\n",
    "# from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# import torch, torchvision\n",
    "# print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# from detectron2.data.datasets import register_coco_instances\n",
    "# register_coco_instances(\"ball\", {}, 'dataset/output_100.json', 'dataset')\n",
    "# register_coco_instances(\"bat\", {}, 'dataset/output_100.json', 'dataset')\n",
    "\n",
    "# ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "# bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "\n",
    "# dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "# from detectron2.engine import DefaultTrainer\n",
    "# from detectron2.checkpoint import DetectionCheckpointer\n",
    "# from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "# from detectron2.data import build_detection_test_loader\n",
    "# from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "# cfg.DATASETS.TRAIN = (\"ball\", \"bat\")\n",
    "# cfg.DATASETS.TEST = (\"ball\", \"bat\")\n",
    "# cfg.DATALOADER.NUM_WORKERS = 0\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")   # Let training initialize from model zoo\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "# cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "# cfg.SOLVER.MAX_ITER = 2000   # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # two class (ball, bat)\n",
    "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "# trainer = DefaultTrainer(cfg)\n",
    "# trainer.resume_or_load(resume=False)\n",
    "# trainer.train()\n",
    "\n",
    "# # # 모델 저장\n",
    "# trainer.checkpointer.save(\"model_final_output100\")\n",
    "\n",
    "import torch, detectron2\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "import time\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import torchvision\n",
    "import requests\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"ball\", {}, 'dataset/output_100.json', 'dataset')\n",
    "register_coco_instances(\"bat\", {}, 'dataset/output_100.json', 'dataset')\n",
    "\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"ball\", \"bat\")\n",
    "cfg.DATASETS.TEST = (\"ball\", \"bat\")\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")   # Let training initialize from model zoo\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # two class(ball, bat)\n",
    "\n",
    "\n",
    "# ->> 처리\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final_output100.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"ball\", \"bat\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "#---- 선수 맞은편 카메라\n",
    "cfg2 = get_cfg()\n",
    "cfg2.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg2.DATASETS.TRAIN = (\"ball\",)\n",
    "cfg2.DATASETS.TEST = (\"ball\", )\n",
    "cfg2.DATALOADER.NUM_WORKERS = 2\n",
    "cfg2.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")   # Let training initialize from model zoo\n",
    "cfg2.MODEL.ROI_HEADS.NUM_CLASSES = 1 # one class(ball)\n",
    "\n",
    "# ->> 처리\n",
    "cfg2.MODEL.WEIGHTS = os.path.join(cfg2.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg2.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold for this model\n",
    "cfg2.DATASETS.TEST = (\"ball\",)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "#----- 끝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/02 16:52:29 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/02 16:52:29 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/02 16:52:29 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/02 16:52:29 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "측면 카메라: False\n",
      "홈플레이트 카메라: True\n",
      "Ball Coordinates:\n",
      "strike!!\n"
     ]
    }
   ],
   "source": [
    "# 함수 선언부\n",
    "def lines_intersect(line1, line2):\n",
    "    \"\"\"Return True if line segment 'line1' and 'line2' intersect. False otherwise.\"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "\n",
    "    # Compute vectors corresponding to lines\n",
    "    px = x2 - x1\n",
    "    py = y2 - y1\n",
    "    qx = x4 - x3\n",
    "    qy = y4 - y3\n",
    "\n",
    "    # Cross product of vectors to determine if parallel\n",
    "    cross_product = px * qy - qx * py\n",
    "    if abs(cross_product) < 1e-8: # consider as zero\n",
    "        return False  # parallel\n",
    "\n",
    "    # Compute the intersection point\n",
    "    dx = x1 - x3\n",
    "    dy = y1 - y3\n",
    "    t = (qx * dy - qy * dx) / cross_product\n",
    "    u = (px * dy - py * dx) / cross_product\n",
    "\n",
    "    return (0 <= t <= 1) and (0 <= u <= 1)\n",
    "\n",
    "# 함수 선언부 끝\n",
    "\n",
    "# 각 파일 path\n",
    "protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"pose_iter_160000.caffemodel\"\n",
    " \n",
    "# Create predictor and metadata objects\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "\n",
    "# 위의 path에 있는 network 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA) #벡엔드로 쿠다를 사용하여 속도향상을 꾀한다\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA) # 쿠다 디바이스에 계산 요청\n",
    "\n",
    "inputWidth=320;\n",
    "inputHeight=240;\n",
    "inputScale=1.0/255;\n",
    "\n",
    "start_time = time.time() # 시작 시간\n",
    "ball_coordinates = []\n",
    "points_buffer = {2: [], 8: [], 9: []} # 버퍼 초기화\n",
    "drawn_line = None\n",
    "line_timestamp = None  # 선의 타임스탬프 변수 초기화\n",
    "\n",
    "strike1 = False  # Initialize strike variable 선수 맞은편 카메라 스트라이크 판정 \n",
    "strike2 = False # 홈플레이트 판정\n",
    "final_strike = False # 최종 스트라이크 판정\n",
    "\n",
    "# 선수 신체부위 추출용 끝\n",
    "\n",
    "video_path1 = '선수 맞은편 카메라.mp4' # 측면카메라\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "\n",
    "# video_path2 = '공 중간으로 지나가는거.mp4' # 홈플레이트 카메라\n",
    "video_path2 = '천장 2.mp4' # 홈플레이트 카메라\n",
    "\n",
    "cap2 = cv2.VideoCapture(video_path2)\n",
    "\n",
    "while cv2.waitKey(1) <0:  #아무 키나 누르면 끝난다.\n",
    "    #웹캠으로부터 영상 가져옴\n",
    "    hasFrame, frame = cap1.read()  \n",
    "    hasFrame2, frame2 = cap2.read() # 홈플레이트\n",
    "    \n",
    "    #웹캠으로부터 영상을 가져올 수 없으면 웹캠 중지\n",
    "    if not hasFrame or not hasFrame2:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "        \n",
    "#     # 프레임 수 계산\n",
    "#     img = cv2.flip(frame, 1)\n",
    "#     curTime = time.time()\t# current time\n",
    "#     fps = 1 / (curTime - start_time)\n",
    "#     start_time = curTime\n",
    "    \n",
    "#     # 프레임 수 문자열에 저장\n",
    "#     fps_str = \"FPS : %0.1f\" %fps\n",
    "\n",
    "#     # 문자열 표시\n",
    "#     cv2.putText(frame, fps_str, (0, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "    \n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth2 = frame2.shape[1]\n",
    "    frameHeight2 = frame2.shape[0]\n",
    "    \n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, inputScale, (inputWidth, inputHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    \n",
    "    imgb=cv2.dnn.imagesFromBlob(inpBlob)\n",
    "    \n",
    "    # network에 넣어주기\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    output = net.forward()\n",
    "    \n",
    "    outputs = predictor2(frame)\n",
    "    v = Visualizer(frame[:, :, ::-1], metadata=ball_metadata)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    confidence_threshold = 0.8 # Set your desired confidence threshold here\n",
    "\n",
    "    for i in range(len(instances)):\n",
    "        if instances.pred_classes[i] == 0: # 0번 클래스는 공입니다.\n",
    "            confidence = instances.scores[i]\n",
    "            if confidence > confidence_threshold:\n",
    "                bbox = instances.pred_boxes[i]\n",
    "                x1, y1, x2, y2 = bbox.tensor.numpy()[0]\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "                radius = int((x2 - x1 + y2 - y1) / 4)\n",
    "                cv2.circle(frame, (center_x, center_y), radius, (255, 0, 0), thickness=2)\n",
    "                ball_coordinates.append((center_x, center_y))  # Add ball coordinates\n",
    "\n",
    "    out = v.draw_instance_predictions(instances)\n",
    "\n",
    "    # 키포인트 검출시 이미지에 그려줌\n",
    "    points = []\n",
    "    for i in [2,8,9]:\n",
    "        # 해당 신체부위 신뢰도 얻음.\n",
    "        probMap = output[0, i, :, :]\n",
    "    \n",
    "        # global 최대값 찾기\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # 원래 이미지에 맞게 점 위치 변경\n",
    "        x = (frameWidth * point[0]) / output.shape[3]\n",
    "        y = (frameHeight * point[1]) / output.shape[2]\n",
    "\n",
    "        # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "        if prob > 0.1 :   \n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "            cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "            points_buffer[i].append((x, y))  # 버퍼에 점 추가\n",
    "        else :\n",
    "            points.append(None)\n",
    "            points_buffer[i] = []  # 버퍼 클리어\n",
    "\n",
    "    # 각 점의 버퍼가 1초 이상의 데이터를 가지고 있다면\n",
    "    if all([len(points_buffer[i]) >= 2*5 for i in [2, 8, 9]]):\n",
    "        # 각 점의 평균 계산\n",
    "        avg_points = {i: np.mean(points_buffer[i], axis=0) for i in [2, 8, 9]}\n",
    "        shoulder_avg, waist_avg, knee_avg = avg_points[2], avg_points[8], avg_points[9]\n",
    "        cal_avg = waist_avg[1] + ((shoulder_avg[1]-waist_avg[1])/2)\n",
    "\n",
    "        # Draw the line\n",
    "        drawn_line = (int(knee_avg[0]), int(knee_avg[1]), int(knee_avg[0]), int(cal_avg))\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "\n",
    "    # 키 포인트 중 하나라도 감지되지 않으면, 최소 1초가 지났는지 확인\n",
    "    if any(pt is None for pt in points):\n",
    "        if line_timestamp is None or time.time() - line_timestamp >= 1:\n",
    "            drawn_line = None\n",
    "            line_timestamp = None\n",
    "\n",
    "    # 이전에 선이 그려졌다면, 그 선을 그리고 타임스탬프를 업데이트\n",
    "    if drawn_line is not None:\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "        line_timestamp = time.time()\n",
    "    \n",
    "    cv2.imshow(\"Side Camera\",frame)\n",
    "\n",
    "    # ------------------------------------------------ 야구\n",
    "    if strike1 == False: # 만약 측면 카메라 판정이 False일 때에만\n",
    "        for i in range(1, len(ball_coordinates)):\n",
    "            ball_trajectory = (*ball_coordinates[i-1], *ball_coordinates[i])  # Get the line of ball's trajectory\n",
    "\n",
    "            if drawn_line is not None and lines_intersect(ball_trajectory, drawn_line):\n",
    "                strike1 = True\n",
    "            else:\n",
    "                strike1 = False\n",
    "\n",
    "  #  print(\"측면 카메라 판정 : \", strike1)\n",
    "# -----------홈플레이트 카메라 부분---------------\n",
    "    outputs2 = predictor(frame2)\n",
    "    v2 = Visualizer(frame2[:, :, ::-1], metadata=ball_metadata, scale=1)\n",
    "    out2 = v2.draw_instance_predictions(outputs2[\"instances\"].to(\"cpu\"))\n",
    "    output_frame2 = out2.get_image()[:, :, ::-1]\n",
    "    output_frame2 = np.array(output_frame2)\n",
    "    instances2 = outputs2[\"instances\"].to(\"cpu\")\n",
    "    num_objects2 = len(instances2)\n",
    "\n",
    "    strike_line_color = (0, 0, 255)  # 라인 색상 (빨간색)\n",
    "    strike_line_left = frameWidth2 * 2 // 10  # 좌측 라인 좌표\n",
    "    strike_line_right = frameWidth2 * 8 // 10  # 우측 라인 좌표\n",
    "    center_line = frameHeight2 // 2\n",
    "\n",
    "    cv2.line(output_frame2, (strike_line_left, 0), (strike_line_left, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (strike_line_right, 0), (strike_line_right, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (0, int(center_line)), (frameWidth2, int(center_line)), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Homeplate Camera\", output_frame2)\n",
    "    \n",
    "    homeplate_confidence_threshold = 0.8 # Set your desired confidence threshold here\n",
    "\n",
    "    ball_indices = [i for i, cls in enumerate(instances2.pred_classes) if cls == 0]  # 공 객체의 인덱스 추출\n",
    "    \n",
    "    if strike2 == False: # 만약 홈플레이트 카메라 판정이 False일 때에만\n",
    "        if any((instances2.pred_boxes.tensor[i][0] > strike_line_left and instances2.pred_boxes.tensor[i][0] < strike_line_right) or\n",
    "            (instances2.pred_boxes.tensor[i][2] > strike_line_left and instances2.pred_boxes.tensor[i][2] < strike_line_right)\n",
    "            for i in ball_indices): # 0:왼쪽상단 2:아래하단 x좌표\n",
    "            strike2 = True\n",
    "          #  print(\"홈플레이트 카메라 판정 : \",strike2)\n",
    "        else:\n",
    "            strike2 = False\n",
    "         #   print(\"홈플레이트 카메라 판정 : \",strike2)\n",
    "\n",
    "    # 배트 객체 인식 확인\n",
    "    bat_indices = [j for j, cls in enumerate(instances2.pred_classes) if cls == 1]  # 배트 객체의 인덱스 추출\n",
    "\n",
    "    if any(instances2.pred_boxes.tensor[j][1] < center_line or instances2.pred_boxes.tensor[j][3] < center_line\n",
    "           for j in bat_indices): # 1:왼쪽상단 3:아래하단 y좌표\n",
    "        final_strike = True\n",
    "        #print(\"배트가 중앙선을 넘었습니다.\")\n",
    "\n",
    "    else:\n",
    "        final_strike = False\n",
    "\n",
    "    # 스트라이크\n",
    "    #if (strike1 == True and strike2 == True) or final_strike == True:\n",
    "     #   break\n",
    "\n",
    "    \n",
    "print(\"측면 카메라:\", strike1)\n",
    "print(\"홈플레이트 카메라:\", strike2)\n",
    "\n",
    "\n",
    "print(\"Ball Coordinates:\")\n",
    "for point in ball_coordinates:\n",
    "    print(point)\n",
    "\n",
    "for i in range(1, len(ball_coordinates)):\n",
    "    ball_trajectory = (*ball_coordinates[i-1], *ball_coordinates[i])  # Get the line of ball's trajectory\n",
    "\n",
    "    if drawn_line is not None and lines_intersect(ball_trajectory, drawn_line):\n",
    "        strike1 = True\n",
    "        break  # Exit the loop if a strike is detected\n",
    "\n",
    "        \n",
    "# 스트라이크\n",
    "if strike1 == True and strike2 == True or final_strike == True:\n",
    "    print(\"strike!!\")\n",
    "# 볼\n",
    "else:\n",
    "    print(\"ball\") \n",
    "        \n",
    "cap2.release()  #카메라 장치에서 받아온 메모리 해제\n",
    "cv2.destroyAllWindows() #모든 윈도우 창 닫음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 복사본 (배트 인식도 수정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/02 16:24:16 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/02 16:24:16 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/02 16:24:16 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[11/02 16:24:16 d2.data.datasets.coco]: \u001b[0mLoaded 100 images in COCO format from dataset/output_100.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "측면 카메라 판정 :  False\n",
      "홈플레이트 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "홈플레이트 카메라 판정 :  True\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라 판정 :  False\n",
      "배트가 중앙선을 넘었습니다.\n",
      "측면 카메라: False\n",
      "홈플레이트 카메라: True\n",
      "strike!!\n"
     ]
    }
   ],
   "source": [
    "# 함수 선언부\n",
    "def lines_intersect(line1, line2):\n",
    "    \"\"\"Return True if line segment 'line1' and 'line2' intersect. False otherwise.\"\"\"\n",
    "    x1, y1, x2, y2 = line1\n",
    "    x3, y3, x4, y4 = line2\n",
    "\n",
    "    # Compute vectors corresponding to lines\n",
    "    px = x2 - x1\n",
    "    py = y2 - y1\n",
    "    qx = x4 - x3\n",
    "    qy = y4 - y3\n",
    "\n",
    "    # Cross product of vectors to determine if parallel\n",
    "    cross_product = px * qy - qx * py\n",
    "    if abs(cross_product) < 1e-8: # consider as zero\n",
    "        return False  # parallel\n",
    "\n",
    "    # Compute the intersection point\n",
    "    dx = x1 - x3\n",
    "    dy = y1 - y3\n",
    "    t = (qx * dy - qy * dx) / cross_product\n",
    "    u = (px * dy - py * dx) / cross_product\n",
    "\n",
    "    return (0 <= t <= 1) and (0 <= u <= 1)\n",
    "\n",
    "# 함수 선언부 끝\n",
    "\n",
    "# 각 파일 path\n",
    "protoFile = \"pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "weightsFile = \"pose_iter_160000.caffemodel\"\n",
    " \n",
    "# Create predictor and metadata objects\n",
    "ball_metadata = MetadataCatalog.get(\"ball\")\n",
    "bat_metadata = MetadataCatalog.get(\"bat\")\n",
    "dataset_dicts = DatasetCatalog.get(\"ball\") + DatasetCatalog.get(\"bat\")\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "predictor2 = DefaultPredictor(cfg2)\n",
    "\n",
    "# 위의 path에 있는 network 불러오기\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA) #벡엔드로 쿠다를 사용하여 속도향상을 꾀한다\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA) # 쿠다 디바이스에 계산 요청\n",
    "\n",
    "inputWidth=320;\n",
    "inputHeight=240;\n",
    "inputScale=1.0/255;\n",
    "\n",
    "start_time = time.time() # 시작 시간\n",
    "ball_coordinates = []\n",
    "points_buffer = {2: [], 8: [], 9: []} # 버퍼 초기화\n",
    "drawn_line = None\n",
    "line_timestamp = None  # 선의 타임스탬프 변수 초기화\n",
    "\n",
    "strike1 = False  # Initialize strike variable 선수 맞은편 카메라 스트라이크 판정 \n",
    "strike2 = False # 홈플레이트 판정\n",
    "final_strike = False # 최종 스트라이크 판정\n",
    "\n",
    "# 선수 신체부위 추출용 끝\n",
    "\n",
    "video_path1 = '선수 맞은편 카메라.mp4' # 측면카메라\n",
    "cap1 = cv2.VideoCapture(1)\n",
    "\n",
    "# video_path2 = '공 중간으로 지나가는거.mp4' # 홈플레이트 카메라\n",
    "video_path2 = 'test2.mp4' # 홈플레이트 카메라\n",
    "\n",
    "cap2 = cv2.VideoCapture(0)\n",
    "\n",
    "while cv2.waitKey(1) <0:  #아무 키나 누르면 끝난다.\n",
    "    #웹캠으로부터 영상 가져옴\n",
    "    hasFrame, frame = cap1.read()  \n",
    "    hasFrame2, frame2 = cap2.read() # 홈플레이트\n",
    "    \n",
    "    #웹캠으로부터 영상을 가져올 수 없으면 웹캠 중지\n",
    "    if not hasFrame or not hasFrame2:\n",
    "        cv2.waitKey()\n",
    "        break\n",
    "        \n",
    "    # 프레임 수 계산\n",
    "    img = cv2.flip(frame, 1)\n",
    "    curTime = time.time()\t# current time\n",
    "    fps = 1 / (curTime - start_time)\n",
    "    start_time = curTime\n",
    "    \n",
    "    # 프레임 수 문자열에 저장\n",
    "    fps_str = \"FPS : %0.1f\" %fps\n",
    "\n",
    "    # 문자열 표시\n",
    "    cv2.putText(frame, fps_str, (0, 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "    \n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth2 = frame2.shape[1]\n",
    "    frameHeight2 = frame2.shape[0]\n",
    "    \n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, inputScale, (inputWidth, inputHeight), (0, 0, 0), swapRB=False, crop=False)\n",
    "    \n",
    "    imgb=cv2.dnn.imagesFromBlob(inpBlob)\n",
    "    \n",
    "    # network에 넣어주기\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    output = net.forward()\n",
    "    \n",
    "    outputs = predictor2(frame)\n",
    "    v = Visualizer(frame[:, :, ::-1], metadata=ball_metadata)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "    confidence_threshold = 0.8 # Set your desired confidence threshold here\n",
    "\n",
    "    for i in range(len(instances)):\n",
    "        if instances.pred_classes[i] == 0: # 0번 클래스는 공입니다.\n",
    "            confidence = instances.scores[i]\n",
    "            if confidence > confidence_threshold:\n",
    "                bbox = instances.pred_boxes[i]\n",
    "                x1, y1, x2, y2 = bbox.tensor.numpy()[0]\n",
    "                center_x = int((x1 + x2) / 2)\n",
    "                center_y = int((y1 + y2) / 2)\n",
    "                radius = int((x2 - x1 + y2 - y1) / 4)\n",
    "                cv2.circle(frame, (center_x, center_y), radius, (255, 0, 0), thickness=2)\n",
    "                ball_coordinates.append((center_x, center_y))  # Add ball coordinates\n",
    "\n",
    "    out = v.draw_instance_predictions(instances)\n",
    "\n",
    "    # 키포인트 검출시 이미지에 그려줌\n",
    "    points = []\n",
    "    for i in [2,8,9]:\n",
    "        # 해당 신체부위 신뢰도 얻음.\n",
    "        probMap = output[0, i, :, :]\n",
    "    \n",
    "        # global 최대값 찾기\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # 원래 이미지에 맞게 점 위치 변경\n",
    "        x = (frameWidth * point[0]) / output.shape[3]\n",
    "        y = (frameHeight * point[1]) / output.shape[2]\n",
    "\n",
    "        # 키포인트 검출한 결과가 0.1보다 크면(검출한곳이 위 BODY_PARTS랑 맞는 부위면) points에 추가, 검출했는데 부위가 없으면 None으로    \n",
    "        if prob > 0.1 :   \n",
    "            cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 255), thickness=-1, lineType=cv2.FILLED) # circle(그릴곳, 원의 중심, 반지름, 색)\n",
    "            cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "            points.append((int(x), int(y)))\n",
    "            points_buffer[i].append((x, y))  # 버퍼에 점 추가\n",
    "        else :\n",
    "            points.append(None)\n",
    "            points_buffer[i] = []  # 버퍼 클리어\n",
    "\n",
    "    # 각 점의 버퍼가 1초 이상의 데이터를 가지고 있다면\n",
    "    if all([len(points_buffer[i]) >= 2*10 for i in [2, 8, 9]]):\n",
    "        # 각 점의 평균 계산\n",
    "        avg_points = {i: np.mean(points_buffer[i], axis=0) for i in [2, 8, 9]}\n",
    "        shoulder_avg, waist_avg, knee_avg = avg_points[2], avg_points[8], avg_points[9]\n",
    "        cal_avg = waist_avg[1] + ((shoulder_avg[1]-waist_avg[1])/2)\n",
    "\n",
    "        # Draw the line\n",
    "        drawn_line = (int(knee_avg[0]), int(knee_avg[1]), int(knee_avg[0]), int(cal_avg))\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "\n",
    "    # 키 포인트 중 하나라도 감지되지 않으면, 최소 1초가 지났는지 확인\n",
    "    if any(pt is None for pt in points):\n",
    "        if line_timestamp is None or time.time() - line_timestamp >= 1:\n",
    "            drawn_line = None\n",
    "            line_timestamp = None\n",
    "\n",
    "    # 이전에 선이 그려졌다면, 그 선을 그리고 타임스탬프를 업데이트\n",
    "    if drawn_line is not None:\n",
    "        cv2.line(frame, (drawn_line[0], drawn_line[1]), (drawn_line[2], drawn_line[3]), (0, 0, 255), 5)\n",
    "        line_timestamp = time.time()\n",
    "    \n",
    "    cv2.imshow(\"Side Camera\",frame)\n",
    "\n",
    "    # ------------------------------------------------ 야구\n",
    "    if strike1 == False: # 만약 측면 카메라 판정이 False일 때에만\n",
    "        for i in range(1, len(ball_coordinates)):\n",
    "            ball_trajectory = (*ball_coordinates[i-1], *ball_coordinates[i])  # Get the line of ball's trajectory\n",
    "\n",
    "            if drawn_line is not None and lines_intersect(ball_trajectory, drawn_line):\n",
    "                strike1 = True\n",
    "            else:\n",
    "                strike1 = False\n",
    "\n",
    "    print(\"측면 카메라 판정 : \", strike1)\n",
    "# -----------홈플레이트 카메라 부분---------------\n",
    "    outputs2 = predictor(frame2)\n",
    "    v2 = Visualizer(frame2[:, :, ::-1], metadata=ball_metadata, scale=1)\n",
    "    out2 = v2.draw_instance_predictions(outputs2[\"instances\"].to(\"cpu\"))\n",
    "    output_frame2 = out2.get_image()[:, :, ::-1]\n",
    "    output_frame2 = np.array(output_frame2)\n",
    "    instances2 = outputs2[\"instances\"].to(\"cpu\")\n",
    "    num_objects2 = len(instances2)\n",
    "    high_confidence_indices = [i for i, score in enumerate(instances2.scores) if score > 0.9]\n",
    "\n",
    "    strike_line_color = (0, 0, 255)  # 라인 색상 (빨간색)\n",
    "    strike_line_left = frameWidth2 * 2 // 10  # 좌측 라인 좌표\n",
    "    strike_line_right = frameWidth2 * 8 // 10  # 우측 라인 좌표\n",
    "    center_line = frameHeight2 // 2\n",
    "\n",
    "    cv2.line(output_frame2, (strike_line_left, 0), (strike_line_left, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (strike_line_right, 0), (strike_line_right, frameHeight2), strike_line_color, 2)\n",
    "    cv2.line(output_frame2, (0, int(center_line)), (frameWidth2, int(center_line)), (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Homeplate Camera\", output_frame2)\n",
    "    \n",
    "#     ball_indices = [i for i, cls in enumerate(instances2.pred_classes) if (cls == 0 and instances2.scores[i] > 0.9)]\n",
    "    ball_indices = [i for i in high_confidence_indices if instances2.pred_classes[i] == 0]\n",
    "    \n",
    "    if strike2 == False: # 만약 홈플레이트 카메라 판정이 False일 때에만\n",
    "        if any((instances2.pred_boxes.tensor[i][0] > strike_line_left and instances2.pred_boxes.tensor[i][0] < strike_line_right) or\n",
    "            (instances2.pred_boxes.tensor[i][2] > strike_line_left and instances2.pred_boxes.tensor[i][2] < strike_line_right)\n",
    "            for i in ball_indices): # 0:왼쪽상단 2:아래하단 x좌표\n",
    "            strike2 = True\n",
    "            print(\"홈플레이트 카메라 판정 : \",strike2) \n",
    "        else:\n",
    "            strike2 = False\n",
    "            print(\"홈플레이트 카메라 판정 : \",strike2)\n",
    "\n",
    "    # 배트 객체 인식 확인\n",
    "#     bat_indices = [j for j, cls in enumerate(instances2.pred_classes) if (cls == 1 and instances2.scores[j] > 0.9)]  # 배트 객체의 인덱스 추출\n",
    "    bat_indices = [i for i in high_confidence_indices if instances2.pred_classes[i] == 1]\n",
    "    \n",
    "    if any(instances2.pred_boxes.tensor[j][1] < center_line or instances2.pred_boxes.tensor[j][3] < center_line\n",
    "           for j in bat_indices): # 1:왼쪽상단 3:아래하단 y좌표\n",
    "        final_strike = True\n",
    "        print(\"배트가 중앙선을 넘었습니다.\")\n",
    "\n",
    "    else:\n",
    "        final_strike = False\n",
    "\n",
    "    # 스트라이크\n",
    "    #if (strike1 == True and strike2 == True) or final_strike == True:\n",
    "     #   break\n",
    "\n",
    "print(\"측면 카메라:\", strike1)\n",
    "print(\"홈플레이트 카메라:\", strike2)\n",
    "\n",
    "# 스트라이크\n",
    "if strike1 == True and strike2 == True or final_strike == True:\n",
    "    print(\"strike!!\")\n",
    "# 볼\n",
    "else:\n",
    "    print(\"ball\") \n",
    "        \n",
    "cap2.release()  #카메라 장치에서 받아온 메모리 해제\n",
    "cv2.destroyAllWindows() #모든 윈도우 창 닫음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
